{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca05097-4fd1-4a68-aac9-b1eb2f8f3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16eb40-f052-41e8-8c2b-404f2273260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image Image manipulation libraries\n",
    "import PIL.Image\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet import ResNet50, preprocess_input\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Concatenate, Input\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a6a34-a1d1-4348-9e70-eec8aedbea15",
   "metadata": {},
   "source": [
    "# Step 1 Data Loading\n",
    "\n",
    "- Download the MNIST data\n",
    "- Download a pretrained model (pretrained for ImageNet classification)\n",
    "- Extract embeddings of the MNIST images from this pretrained model\n",
    "- Convert data into correct format (tensors) and plot two input-output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd174da-c2df-4d69-87ec-6b018e7e7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d2b80-d49f-49d2-886e-8e32e073f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc03adc-983b-4cf5-a404-463c420a0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 19:11:59.504762: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-07 19:11:59.504785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (KARZA-HW-0270): /proc/driver/nvidia/version does not exist\n",
      "2023-03-07 19:11:59.505007: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create resnet50 model for feature extraction\n",
    "new_input = Input(shape=(28, 28, 3))\n",
    "res = ResNet50(include_top=False, input_tensor=new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73c8db-e068-4df6-a59d-ba21dda1857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings in batches\n",
    "# Function to create batches of data from the provided input data\n",
    "\n",
    "\n",
    "def create_batches(X, batch_size=32):\n",
    "\n",
    "    # With the given batch size, find the total number of batches\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "\n",
    "    # Last batch could've been fractional and may get ignored hence increment n_batches by one\n",
    "    n_batches += 1\n",
    "\n",
    "    # Loop over all the data for n_batches times to create the batch\n",
    "    all_batches = []\n",
    "    for batch in tqdm(range(n_batches), total=n_batches, desc=\"Creating batches...\"):\n",
    "        try:\n",
    "\n",
    "            # Subset into the batch dimension of the numpy array\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "            images = X[start:end, :, :]\n",
    "            preprocessed_images = []\n",
    "\n",
    "            # Process each image in the batch\n",
    "            if len(images) > 0:\n",
    "                for image in images:\n",
    "                    # Create the numpy array into a 1-D grayscale PIL Image\n",
    "                    # Post that convert that image into an RGB image since the\n",
    "                    # pretrained model was trained on 3-channel images\n",
    "                    image = np.array(PIL.Image.fromarray(image).convert(\"RGB\"))\n",
    "                    image = image.reshape((1, *image.shape))\n",
    "                    preprocessed_images.append(image)\n",
    "\n",
    "                # Create a tensor out of this batch\n",
    "                batch_tensor = Concatenate(axis=0)(preprocessed_images)\n",
    "\n",
    "                # Add these batches to a list\n",
    "                all_batches.append(batch_tensor)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "\n",
    "    # Return the list of all the batches\n",
    "    return all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c31248-cbcd-45ae-aa0c-36b151821ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating batches...: 100%|█████████████████| 1876/1876 [00:05<00:00, 349.99it/s]\n",
      "Creating batches...: 100%|███████████████████| 313/313 [00:00<00:00, 346.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a set of train and validation batches with the help of above function\n",
    "train_batches = create_batches(X_train)\n",
    "test_batches = create_batches(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73ca59-1241-42e4-8958-6c023df9fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the resnet embeddings for the images\n",
    "def get_embeddings(batched_data):\n",
    "    embeddings = []\n",
    "    for batch in tqdm(batched_data, total=len(batched_data)):\n",
    "        embeddings.append(res.predict(batch, verbose=0))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5d7ef-e374-4aad-a523-65c8777f1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1875/1875 [02:56<00:00, 10.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the train embeddings\n",
    "train_embeds = get_embeddings(train_batches)\n",
    "train_embeds = np.concatenate(train_embeds, axis=0)\n",
    "train_embeds = train_embeds[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2632fd4-4c7c-4bd9-9eb6-64b3b28743b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 313/313 [00:29<00:00, 10.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the test embeddings\n",
    "test_embeds = get_embeddings(test_batces)\n",
    "test_embeds = np.concatenate(test_embeds, axis=0)\n",
    "test_embeds = test_embeds[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86a5e0-1ec5-4fdf-9b2b-6a9ba734ec19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 2048), (10000, 2048))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeds.shape, test_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516808f-e82a-4326-8582-05e332b6aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the embeddings along with labels in pickle file \n",
    "# This is to persist the data and to look at the same for any subsequent analysis\n",
    "\n",
    "data = {\n",
    "    \"train\": {\"embeddings\": train_embeds, \"labels\": y_train},\n",
    "    \"test\": {\"embeddings\": test_embeds, \"labels\": y_test},\n",
    "}\n",
    "\n",
    "pickle.dump(data, open(\"data/embeddings_with_labels.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
