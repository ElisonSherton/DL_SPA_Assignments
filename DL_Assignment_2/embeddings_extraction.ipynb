{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca05097-4fd1-4a68-aac9-b1eb2f8f3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16eb40-f052-41e8-8c2b-404f2273260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 22:18:07.963837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 22:18:08.105021: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-06 22:18:08.107867: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-06 22:18:08.107880: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-06 22:18:08.733781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-06 22:18:08.733822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-06 22:18:08.733828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Import resnet50 model from keras\n",
    "from keras.applications.resnet import ResNet50, preprocess_input\n",
    "from keras.layers import Input\n",
    "\n",
    "# Image libraries\n",
    "import PIL.Image\n",
    "\n",
    "# Linear Algebra Libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd174da-c2df-4d69-87ec-6b018e7e7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d2b80-d49f-49d2-886e-8e32e073f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc03adc-983b-4cf5-a404-463c420a0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resnet50 model for feature extraction\n",
    "new_input = Input(shape=(28, 28, 3))\n",
    "res = ResNet50(include_top = False, input_tensor = new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bc7cf-bdd5-45bd-96c4-f2772c89abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73c8db-e068-4df6-a59d-ba21dda1857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(X, batch_size = 32):\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "    n_batches += 1\n",
    "    all_batches = []\n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end   = start + batch_size\n",
    "        images = X[start:end, :, :]\n",
    "        preprocessed_images = []\n",
    "        for image in images:\n",
    "            image = np.array(PIL.Image.fromarray(image).convert(\"RGB\"))\n",
    "            image = image.reshape((1, *image.shape))\n",
    "            preprocessed_images.append(image)\n",
    "        batch_tensor = Concatenate(axis = 0)(preprocessed_images)\n",
    "        all_batches.append(batch_tensor)\n",
    "        break\n",
    "    return all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c31248-cbcd-45ae-aa0c-36b151821ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "btchs = create_batches(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2632fd4-4c7c-4bd9-9eb6-64b3b28743b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n"
     ]
    }
   ],
   "source": [
    "embeddings = res.predict(btchs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78949b-1431-4de0-b11f-ef097edc9609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 1, 2048)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
