{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed0ae90-6f15-43ea-bed5-8e4d1b341b7d",
   "metadata": {},
   "source": [
    "# SPA Assignment 1\n",
    "\n",
    "**Group Number 97**\n",
    "\n",
    "|No.|Member|Student ID|\n",
    "|--|--|--|\n",
    "|1|Shreysi Kalra|2021fc04586|\n",
    "|2|Vinayak Nayak|2021fc04135|\n",
    "|3|Ajith Praveen R|2021fc04329|\n",
    "\n",
    "\n",
    "**Streaming Analytics**\n",
    "\n",
    "\n",
    "You are appointed as a Streaming Analytics expert for a firm which is looking for utilizing the solutions / platforms available from the Streaming Analytics space. As the firms maturity level in the big data space is at very nascent stage, you need to help them to understand how Streaming Analytics is helpful in their several use cases and also further on identifying the various options of tools and platforms those can be leveraged for this activity. \n",
    "\n",
    "Amazon Web Service (AWS) is leading player in the space of cloud computing. They have developed a special cloud service named “Amazon Kinesis” exclusively for handling various streaming analytics use cases in very simpler manner. To introduce these services to the world, they also have prepared a nice documentation – part of which also contains the white paper. You can refer to this white paper which can help you while interacting with the client. \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934c047-4f96-4ab0-8626-3558b60033fe",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "You need to introduce the client with several examples where streaming analytics has already been used. For that purpose, you need to formulate one example of each type of Real-time application scenarios mentioned in the white paper.  \n",
    "- The example should be different from the ones discussed in the document\n",
    "- Narration should have \n",
    "  - brief description of the use case scenario\n",
    "  - short explanation about how it can leverage streaming analytics solutions / platforms\n",
    "  - justification about how it falls under the particular category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb5417-cb16-43f2-a6c5-fd6235812618",
   "metadata": {},
   "source": [
    "**Client Pitch**\n",
    "\n",
    "In today's fast paced real world, data is the new oil. Lots of data is being generated at an ever increasing pace and it holds the keys to unlock a lot of opportunities for business. Previously, CoEs would munge over the data for days/weeks and come up with reasonable meaningful insights which could help the business/organization identify new opportunities and decide their action plan accordingly. That still happens in the today's world, but over the course of last decade or so, attention spans of people have reduced and technological advances have been huge which has fuelled the need for instant gratification much more. *So, we need to draw* ***actionable insights***  *from* ***lots of data*** *over both* ***smaller and bigger timespans*** *to best suit the needs of end users/businesses*.\n",
    "\n",
    "To elaborate, there are two main processing patterns – `Stream processing` which expects real/near-real time analysis and responses to events in data streams; And `Batch processing` where some analysis is done periodically over hours/days/fortnight/mmonth and the results of this analysis are used to drive the underlying process/phenomenon forward. \n",
    "\n",
    "Let us understand this further with an example or a real time application in Auto Industry. Streaming data and real time analytics are disrupting the rental car industry. \n",
    "\n",
    "These days, renting a car for family vacation is commonplace. Safety is a central aspect which no user would compromise on. Can the rental company predict breakdown and alert their drivers to take the necessary action in earnest? Can they provide incentives to drivers based on their driving behaviors like speeding or fuel efficiency? Could they alert the driver whether or not s/he is authorized to drive into/out of a particular geographical region? This is possible using a network of vehicles/cars connected amongst themselves over the web with the use of `Stream-Processing` and `Batch-Processing` architectures.\n",
    "\n",
    "Here, data collected can be categorized as :\n",
    "\n",
    "- Behavioral Data – Track driver’s use of vehicle using indicators like speed, steering, braking and fuel efficient driving. Data can be used to award incentives or recognitions for good driving behavior and/or provide constructive feedback in case of rash/irresponsible driving.\n",
    "- Diagnostic Data – Track the health of vehicle using indicators like engine temperature, tyre pressure, fuel tank etc. and notify drivers when a checkup/maintainence/service is required\n",
    " \n",
    "\n",
    "**Requirement 1 – Predict breakdown and alert drivers (stream processing architecture)**\n",
    "\n",
    "Diagnostic data enables car rental agencies to assess the heath of a vehicle and notify drivers when a service is required with in car voice communication. This is a classic example of building a real time analytics solution. This will comprise of two components –\n",
    "\n",
    "* First, stream processors continuously collect & parse data from sources such as sensors fitted within the car as it occurs and then delivers data to a streaming transport system\n",
    "* Secondly, streaming analytics solution consume data from streaming transport systems over a limited time window that allows for data manipulation, enrichment and analysis\n",
    "* Ultimately data is delivered for a variety of uses such as alerting, real time visualization or persisting event data for historical analysis later.\n",
    "\n",
    "![](qn1_1.png)\n",
    "\n",
    "\n",
    "**Requirement 2 – Recognize good driving behavior (batch or micro batch processing architecture)**\n",
    "\n",
    "Behavioral data like the speed of the vehicle, braking information and fuel efficiency can be sent to Kinesis Firehose so that they are stored within an S3 bucket. The analytics application can later connect to S3 to perform analysis and identify drivers with good, average or bad driving behaviors. People with good driving behaviors can be provided with some personalized offers for any subsequent car hires.\n",
    "\n",
    "Since this doesn’t require any real time analytics, therefore the application can consume the events data stored within S3 later in the day to calculate driver efficiency scores based on which the recommendations or future incentives are provided. And since it doesn’t involve real time stream analytics, therefore this can be categorized under batch or micro-batch processing architecture.\n",
    "\n",
    "![](qn1_2.png)\n",
    "\n",
    "Amazon Kinesis Data firehose is the easiest way to reliably load streaming data into data lakes, data stores and analytic tools. It can capture, transform and load streaming data into S3, Redshift or Elastic Search. Splunk enables near real time analytics with existing business intelligence tools and dashboards\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06e706-6816-4c03-8520-2f54bac29ee5",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "You are in a meeting with the firm’s management who are little bit concerned about the challenges associated with streaming analytics. The white paper describes few challenges faced while adapting the streaming analytics. In order to assist the client "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ee26e-21ed-4075-9ac4-75441d849e69",
   "metadata": {},
   "source": [
    "**Briefly narrate the four critical challenges in your own words**\n",
    "\n",
    "*Critical Challenges*\n",
    "\n",
    "Some critical challenges faced with real time stream processing analytics include the following –\n",
    "\n",
    "* Developing and maintaining custom streaming data pipelines is cumbersome and resource intensive as it involves collecting, preparing, and transmitting data being generated simultaneously plethora of data sources.\n",
    "* Storage and compute come at a cost; they must be efficiently utilized to retrieve & transmit data efficiently for maximum performance, low latency, high throughput and so on.\n",
    "* High number of servers or compute capacity may be required to accommodate varying speeds of incoming data\n",
    "* Monitoring the system and recovering from any server or network failures without creating duplicate data will be essential\n",
    "* Consumes huge amount of time to have a system developed on our own and also costs enormous money to own and maintain servers\n",
    "* Load Balancing\n",
    "* Resource Maintainence\n",
    " \n",
    "\n",
    "**Identify the different tools that can be used to resolve / mitigate those challenges**\n",
    "\n",
    "AWS real time data streaming services  (Like Kinesis) enable us to collect, process and analyze continuous streaming data at scale and take necessary action as and when needed. We can build real time applications and leverage secure, highly available, durable and scalable managed services provided by AWS. Some tools / services that can be used to address the highlighted challenges are as follows.\n",
    "\n",
    "\n",
    "1. Stream Ingestion – Services like API Gateway, AWS IoT Core enables integration with continuous data produced from various data sources in a durable and secure manner. AWS Cloudwatch stores log streams for a lot of services which could also be used at a later point in time for analysing anomalies, or service breakdowns/failures etc.\n",
    "\n",
    "2. Stream Storage – We can choose between Amazon Kinesis Data Streams, Kinesis Data Firehose and Managed Streaming for Apache Kafka (MSK) that meets our storage needs based on scaling, latency and processing requirements.\n",
    "\n",
    "3. Stream Processing – We can choose a selection of services ranging from solutions to transform and deliver data continuously to a destination like Kinesis Data Firehose to real time applications and machine learning integrations like Amazon Kinesis Data Analytics and Apache Druid etc.\n",
    "\n",
    "4. Destination – Deliver streaming data to data lakes, data warehouses and analytics services like S3, Redshift, Elastic Search Services and Amazon EMR\n",
    "\n",
    "\n",
    "**Address how each of the challenge is resolved with the tools / platforms identified**\n",
    "\n",
    "- Using the managed services provided by AWS, we will be able to create the required server infrastructure within few clicks and therefore the set-up time to have an environment up and running is drastically reduced\n",
    "- Storage systems like S3 is most cost effective and also processing elements like Lambda are serverless and therefore they are the most efficient and cost-effective ways to store and compute\n",
    "- Auto scaling is handled by the managed service and therefore the number of shards / servers involved in Kinesis data stream is increased or reduced based on the data volume that it needs to handle at that given point in time\n",
    "- AWS Monitoring and ensuring data pipeline is created across different availability zones helps in case of a server or network failover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b760d79-9e9c-4b10-89e5-487fc63798f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb665792-f349-4915-90dc-1b84546c7ac3",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "The white paper discusses three different use cases which the toll station company has addressed using streaming data. But the solution is described in terms of various cloud services offered by AWS. The client does not have the knowledge about the cloud computing and AWS. In fact all the three use cases can be very well addressed with a general architecture used in the big data analytics and streaming analytics. You need to work upon helping client to understand those common architectures.  \n",
    "- Identify the architecture that can be fitted well for capturing all three use cases \n",
    "- Convert the final architecture diagram provided by AWS team into an architecture diagram based upon your answer to earlier question\n",
    "- Take care that all three cases should be vividly coming out of the architecture diagram, if required add brief description about each flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929876af-fa40-4c15-8238-f4ac06c4802f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a393878a-e076-46ff-955c-4b548ec81d6d",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "The client is now impressed with the capabilities of the AWS and how it’s streamlining the application development and deployment. But they also want to discover more on the open source tools / platforms that can be leveraged. As a result, you need to work upon identifying the open source tools for each of the use case. \n",
    "- For each of the use case\n",
    "  - Identify the tools / platforms that can be used to solve it\n",
    "  - Draw a solution diagram using the tools identified in earlier question the flow should come out clearly from the solution diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d34db-61e0-4328-b226-2169958cb1ef",
   "metadata": {},
   "source": [
    "Open Source Alternatives to the services used in the above architecture diagram are as follows\n",
    "\n",
    "|AWS Service|Opensource Service|\n",
    "|--|--|\n",
    "|AWS S3|  HDFS |\n",
    "|AWS Kinesis| Apache Kafka|\n",
    "|AWS Kinesis Data Analytics| Apache Druid|\n",
    "|DynamoDB| MongoDB/MongoDB Atlas|\n",
    "|AWS Lambda| Dedicated On Prem Servers|\n",
    "|AWS Redshift| PostGreSQL|\n",
    "\n",
    "The final solution diagram after incorporating the above services looks as follows:\n",
    "![](open_source_framework.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
